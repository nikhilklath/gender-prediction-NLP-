{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Import the required Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import random \n",
    "from nltk.corpus import names \n",
    "import nltk \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "source": [
    "### Create a function that uses Naive Bayesian Classifier to generate generate predictions based on training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word): \n",
    "    return {'last_2letters':word[-2:], 'last_letter':word[-1], 'last_3letter':word[-3:],'last_4letter':word[-4:],'first_letter':word[0], 'first_2letter':word[:2]} \n",
    "  \n",
    "def get_prediction(country, male, female):\n",
    "    # preparing a list of examples and corresponding class labels. \n",
    "    labeled_names = ([(name.split(' ')[0], 'male') for name in male['given_name']]+\n",
    "             [(name.split(' ')[0], 'female') for name in female['given_name']])\n",
    "\n",
    "    n = len(male) + len(female) \n",
    "  \n",
    "    random.shuffle(labeled_names) \n",
    "  \n",
    "    # we use the feature extractor to process the names data. \n",
    "    featuresets = [(gender_features(n), gender)  \n",
    "               for (n, gender)in labeled_names] \n",
    "  \n",
    "    # Divide the resulting list of feature sets into a training set and a test set. \n",
    "    train_set, test_set = featuresets[:n-100], featuresets[n-100:] \n",
    "  \n",
    "    # The training set is used to train a new \"naive Bayes\" classifier. \n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)   \n",
    "    #print(country, nltk.classify.accuracy(classifier, train_set))\n",
    "    #print(country, nltk.classify.accuracy(classifier, test_set))\n",
    "    #classifier.show_most_informative_features(200)\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "source": [
    "### Load the excel file that contains list of scientists whose gender is available"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the excel file into a datafram\n",
    "gender = pd.read_excel(\"F:\\BU Sem 3\\RA NBER\\listofauthorswithfirstname_Encoded\\listofauthorswithfirstname_Encoded.xlsx\")\n",
    "\n",
    "# set author id as index\n",
    "gender = gender.set_index(\"author_id\") \n",
    "\n",
    "# save author's gender as dictionary\n",
    "gender_dic = gender[\"GENDER\"].to_dict() "
   ]
  },
  {
   "source": [
    "### Load the excel file that contains the list of authors with their country"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = pd.read_csv(\"F:\\BU Sem 3\\RA NBER\\scopus_authors.tofind.csv\")\n",
    "\n",
    "# set author id as index\n",
    "country = country.set_index(\"author_id\") \n",
    "\n",
    "# save author's country as dictionary\n",
    "country_dic = country[\"affiliation_country\"].to_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If author's gender is not available, assign gender= 4\n",
    "for id in country.index:\n",
    "    if id in gender.index:\n",
    "        country.loc[id, \"gender\"] = gender_dic[id]\n",
    "    else:\n",
    "        country.loc[id, \"gender\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "country.to_excel(\"F:\\BU Sem 3\\RA NBER/auth_gend_coun.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = pd.read_excel(\"F:\\BU Sem 3\\RA NBER/auth_gend_coun.xlsx\")\n",
    "country = country.set_index(\"author_id\")"
   ]
  },
  {
   "source": [
    "### Predict gender for all authors whose gender is not available using gender of authors from that country as training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = country.affiliation_country.unique()\n",
    "for c in countries:\n",
    "    print(c)\n",
    "\n",
    "    # all male authors in that country\n",
    "    male = gender[(gender['GENDER']==1) & (gender['Country']==c)] \n",
    "\n",
    "     # all female authors in that country\n",
    "    female = gender[(gender['GENDER']==2) & (gender['Country']==c)]\n",
    "\n",
    "    # generate a gender classifier for that country\n",
    "    globals()[\"classify_\"+c] = get_prediction(c, male, female) \n",
    "\n",
    "    df = country[country[\"Country\"]==c]\n",
    "    for id in df.index.unique():\n",
    "        # get the name of the author\n",
    "        name = df.at[id, \"given_name\"]\n",
    "\n",
    "        # predict author's name \n",
    "        country.loc[id, \"gender_pred\"] = globals()[\"classify_\"+c].classify(gender_features(str(name).split(' ')[0]))\n",
    "\n",
    "        # dummy for whether gender was already assigned before prediction\n",
    "        country.loc[id, \"pred_dummy\"] = not(df.loc[id,\"gender\"]==1 or df.loc[id,\"gender\"]==2)"
   ]
  },
  {
   "source": [
    "### Add this data to the author-publication long dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = 'F:\\BU Sem 3\\RA NBER\\long data/'\n",
    "dir = os.listdir(orig)\n",
    "for each in dir:\n",
    "    # for every file\n",
    "\n",
    "    # load the excel spreadsheet\n",
    "    auth_data = pd.read_excel(orig+each)\n",
    "\n",
    "    # subset data frame for focal authors whose gender is needed\n",
    "    auth_sub = auth_data[auth_data[\"focal author\"] == True]\n",
    "\n",
    "    # set author id as index\n",
    "    auth_sub = auth_sub.set_index(\"auid\")\n",
    "    for id in auth_sub.index.unique():\n",
    "\n",
    "        # add author's country, gender, predicted gender and dummy\n",
    "        auth_sub.loc[id, \"country\"] = country.loc[id,\"affiliation_country\"]\n",
    "        auth_sub.loc[id, \"gender\"] = country.loc[id,\"gender\"]\n",
    "        auth_sub.loc[id, \"gender_pred\"] = country.loc[id,\"gender_pred\"]\n",
    "        auth_sub.loc[id, \"pred_dummy\"] = country.loc[id,\"pred_dummy\"]\n",
    "        \n",
    "        # create dictionaries for above variables\n",
    "        country_dic = auth_sub[\"country\"].to_dict()\n",
    "        gender_dic = auth_sub[\"gender\"].to_dict()\n",
    "        gender_pred_dic = auth_sub[\"gender_pred\"].to_dict()\n",
    "        pred_dummy_dic = auth_sub[\"pred_dummy\"].to_dict()\n",
    "        \n",
    "        # map the dictioary to the long dataset\n",
    "        auth_data[\"country\"] = auth_data['auid'].map(country_dic)\n",
    "        auth_data[\"gender\"] = auth_data['auid'].map(gender_dic)\n",
    "        auth_data[\"gender_pred\"] = auth_data['auid'].map(gender_pred_dic)\n",
    "        auth_data[\"pred_dummy\"] = auth_data['auid'].map(pred_dummy_dic)\n",
    "    auth_data.to_excel(orig+each)"
   ]
  }
 ]
}